# adversarial-prompt-defense-for-GPT
this repo has a specific focus on defending against "adversarial prompts." Adversarial prompts can be used to manipulate the system into generating undesired content, and this Python script attempts to alleviate this concern by detecting potential objectionable content in real time
